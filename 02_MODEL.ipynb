{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import unicodedata\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data_path = 'data/dobre-slowa.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of this dataset is  (1164,)\n"
     ]
    }
   ],
   "source": [
    "all_words = np.asarray(pd.read_csv(clean_data_path, sep=\" \", header=None).T)\n",
    "all_words = all_words.reshape(-1,)\n",
    "print(\"The shape of this dataset is \",np.shape(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = np.array([word for word in all_words if type(word) is str]).T\n",
    "all_letters = \"\".join((set(str(set(list(set(all_words)))))))\n",
    "n_letters = len(all_letters) + 1 # Plus EOS marker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ŁS£EYĄÓU}W{GKŚFŻŹ-ÒML'HĘPADRJTŃOCIBN ,ZĆ\""
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_letters = \"\"\n",
    "\n",
    "# for ch in all_words:\n",
    "#     if ch in all_letters:\n",
    "#         pass\n",
    "#     else:\n",
    "#         all_letters+=ch\n",
    "# # all_letters = [for ch in _all_words if ch is not in all_letters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove_chars_list = [\",\",\"-\",\"£\",\"Ò\",\"[\",\"]\"]\n",
    "\n",
    "# for ch in remove_chars_list:\n",
    "#         all_letters.remove(ch)      \n",
    "        \n",
    "# n_letters = len(all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # check that all words use characters within the range I defined [all_letters]\n",
    "\n",
    "\n",
    "# for _, word in enumerate(all_words, 0):\n",
    "# #     print(n, word)\n",
    "#     i = _\n",
    "#     if type(word) == str:\n",
    "#         all_words = np.delete(word, i, 0)\n",
    "#         i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, input, hidden):\n",
    "#         input_combined = torch.cat((input, hidden))\n",
    "#         input_combined = torch.cat((input, hidden), 1)\n",
    "\n",
    "#         hidden = self.i2h(input_combined)\n",
    "#         output = self.i2o(input_combined)\n",
    "#         output_combined = torch.cat((hidden, output), 1)\n",
    "#         output = self.o2o(output_combined)\n",
    "#         output = self.dropout(output)\n",
    "#         output = self.softmax(output)\n",
    "#         return output, hidden\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input_combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inputTensor(word):\n",
    "    '''\n",
    "    Creates a tensor of shape len(word), 1, n_letters \n",
    "    that one-hot encodes letters of each word'''\n",
    "    tensor = torch.zeros(len(word),1,n_letters)\n",
    "    \n",
    "    for n, letter in enumerate(word):\n",
    "        tensor[n][0][all_letters.find(letter)] = 1\n",
    "    \n",
    "    return tensor\n",
    "\n",
    "#test\n",
    "# inputTensor(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word = \"abc\"\n",
    "\n",
    "# tensor = np.zeros([len(word),n_letters])\n",
    "\n",
    "# for n, letter in enumerate(word):\n",
    "#     tensor[n][all_letters.find(letter)] = 1\n",
    "\n",
    "# tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "\n",
       "Columns 0 to 18 \n",
       "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "\n",
       "Columns 19 to 37 \n",
       "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "\n",
       "Columns 38 to 40 \n",
       "    0   0   1\n",
       "\n",
       "(1 ,.,.) = \n",
       "\n",
       "Columns 0 to 18 \n",
       "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "\n",
       "Columns 19 to 37 \n",
       "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "\n",
       "Columns 38 to 40 \n",
       "    0   0   1\n",
       "\n",
       "(2 ,.,.) = \n",
       "\n",
       "Columns 0 to 18 \n",
       "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "\n",
       "Columns 19 to 37 \n",
       "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "\n",
       "Columns 38 to 40 \n",
       "    0   0   1\n",
       "[torch.FloatTensor of size 3x1x41]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputTensor(\"abc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def targetTensor(word):\n",
    "    letter_indexes = [all_letters.find(word[li]) for li in range(1, len(word))] # finds the index of each letter of a word and puts it in a list \n",
    "    letter_indexes.append(n_letters - 1) # adds EOS character at the end so the network can learn where words stop\n",
    "    \n",
    "    return torch.LongTensor(letter_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# letter_indexes = [all_letters.find(word[li]) for li in range(1, len(word))] \n",
    "# letter_indexes.append(n_letters - 1) # EOS\n",
    "# letter_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make category, input, and target tensors from a random category, line pair\n",
    "def randomTrainingExample():\n",
    "    word = np.random.choice(all_words)\n",
    "\n",
    "    input_line_tensor = Variable(inputTensor(word))\n",
    "    target_line_tensor = Variable(targetTensor(word))\n",
    "    \n",
    "    return input_line_tensor, target_line_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_line_tensor, target_line_tensor = randomTrainingExample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_line_tensor.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define the loss function\n",
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(input_line_tensor, target_line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(input_line_tensor.size()[0]):\n",
    "#         output, hidden = rnn(1, input_line_tensor[i], hidden)\n",
    "        output, hidden = rnn(input_line_tensor[i], hidden)\n",
    "        loss += criterion(output, target_line_tensor[i])\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.data[0] / input_line_tensor.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 18s (5000 5%) 2.8494\n",
      "0m 36s (10000 10%) 2.6956\n",
      "0m 54s (15000 15%) 2.7291\n",
      "1m 12s (20000 20%) 2.3491\n",
      "1m 30s (25000 25%) 3.0178\n",
      "1m 48s (30000 30%) 2.3648\n",
      "2m 5s (35000 35%) 2.2196\n",
      "2m 23s (40000 40%) 3.0767\n",
      "2m 41s (45000 45%) 2.2420\n",
      "2m 58s (50000 50%) 2.7659\n",
      "3m 16s (55000 55%) 2.1741\n",
      "3m 34s (60000 60%) 2.6731\n",
      "3m 52s (65000 65%) 3.0617\n",
      "4m 10s (70000 70%) 3.1600\n",
      "4m 27s (75000 75%) 2.1098\n",
      "4m 45s (80000 80%) 2.4026\n",
      "5m 2s (85000 85%) 2.9225\n",
      "5m 20s (90000 90%) 1.9190\n",
      "5m 38s (95000 95%) 1.8451\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(n_letters, 128, n_letters)\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 500\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters):\n",
    "    output, loss = train(*randomTrainingExample())\n",
    "\n",
    "    total_loss += loss\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "\n",
    "def sample(start_letter='A'):\n",
    "    input = Variable(inputTensor(start_letter))\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    output_name = start_letter\n",
    "\n",
    "    for i in range(max_length):\n",
    "        output, hidden = rnn(input[0], hidden)\n",
    "        topv, topi = output.data.topk(1)\n",
    "        topi = topi[0][0]\n",
    "        if topi == n_letters - 1:\n",
    "            break\n",
    "        else:\n",
    "            letter = all_letters[topi]\n",
    "            output_name += letter\n",
    "        input = Variable(inputTensor(letter))\n",
    "\n",
    "    return output_name\n",
    "\n",
    "# Get multiple samples multiple starting letters\n",
    "def samples(start_letters='ABC'):\n",
    "    for start_letter in start_letters:\n",
    "        print(sample(category, start_letter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = []\n",
    "for i in range(0,100):\n",
    "    name = sample(random.choice(all_letters[:26]))\n",
    "\n",
    "    names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. characters to delete from list of letters and list of words [\"'\", \"-\"]\n",
    "# 2. get more words from the chat\n",
    "# 3. get train/validation curves going (from pytorch on github)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'ARATORA\",\n",
       " \"'AROTA\",\n",
       " \"'AROTER\",\n",
       " '-USTON',\n",
       " '-USTONA',\n",
       " '-USZA',\n",
       " 'ABURA',\n",
       " 'ARGANT',\n",
       " 'ELIEK',\n",
       " 'ERBALANIE',\n",
       " 'ERBALATA',\n",
       " 'EROWORA',\n",
       " 'FARDEK',\n",
       " 'FAROTAR',\n",
       " 'FAROTER',\n",
       " 'FAROTERA',\n",
       " 'GANTOR',\n",
       " 'GANTORA',\n",
       " 'GASZANA',\n",
       " 'HABASTARA',\n",
       " 'HARAPA',\n",
       " 'HARATARA',\n",
       " 'KARATA',\n",
       " 'KURA',\n",
       " 'LAPA',\n",
       " 'MARONE',\n",
       " 'PARANIER',\n",
       " 'SZERZEK',\n",
       " 'URA',\n",
       " 'URDASZAKA',\n",
       " 'WIARONA',\n",
       " 'WIARONITA',\n",
       " 'YMARONA',\n",
       " '{ARATARA',\n",
       " '{ARATARANT',\n",
       " '{ARATARAS',\n",
       " '}ABARA',\n",
       " '}URA',\n",
       " '}URAST',\n",
       " '}URESTAR',\n",
       " '£ABIERA',\n",
       " '£APA',\n",
       " '£APATAR',\n",
       " '£APIER',\n",
       " '£APIORON',\n",
       " 'ÒUSZA',\n",
       " 'ÒUSZY',\n",
       " 'ÓRMANIA',\n",
       " 'ÓRZAPA',\n",
       " 'ÓRZASZA',\n",
       " 'ĄKAROTEK',\n",
       " 'ĄLENIER',\n",
       " 'ĄLIA',\n",
       " 'ĄLIEK',\n",
       " 'ĘKA',\n",
       " 'ĘRA',\n",
       " 'ŁAKARA',\n",
       " 'ŁAPA',\n",
       " 'ŁAPAT',\n",
       " 'ŁAPATA',\n",
       " 'ŚLIEKA',\n",
       " 'ŚLIET',\n",
       " 'ŹUSTA',\n",
       " 'ŹUSZA',\n",
       " 'ŹUSZANA',\n",
       " 'ŻARA',\n",
       " 'ŻERA'}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.646141505305164,\n",
       " 3.374614871917972,\n",
       " 3.1494420618421253,\n",
       " 3.087653164578818,\n",
       " 3.085079353526094,\n",
       " 3.0697253644472307,\n",
       " 3.0174152024801386,\n",
       " 3.005689270304683,\n",
       " 2.974623954750073,\n",
       " 2.972647937347443,\n",
       " 2.9692522529170247,\n",
       " 2.9452913924219084,\n",
       " 2.948169062657812,\n",
       " 2.9195080995621954,\n",
       " 2.9240061042781456,\n",
       " 2.9174387143363574,\n",
       " 2.874018387477622,\n",
       " 2.8625354365966738,\n",
       " 2.861607991249628,\n",
       " 2.8349373824650357,\n",
       " 2.826796599397366,\n",
       " 2.8286069992677394,\n",
       " 2.82763317059659,\n",
       " 2.8195197922076334,\n",
       " 2.7991198958393717,\n",
       " 2.815273891991436,\n",
       " 2.7994589371063086,\n",
       " 2.792246321133117,\n",
       " 2.740881548675072,\n",
       " 2.7583068777217563,\n",
       " 2.742113296814816,\n",
       " 2.7517712165829105,\n",
       " 2.724739434037693,\n",
       " 2.7267178177772156,\n",
       " 2.698411558118341,\n",
       " 2.716265667802491,\n",
       " 2.6983360394214144,\n",
       " 2.685111469778659,\n",
       " 2.69637869038197,\n",
       " 2.6780475400534276,\n",
       " 2.6860011650851807,\n",
       " 2.6640460751071897,\n",
       " 2.6785044231865696,\n",
       " 2.691172421434565,\n",
       " 2.6463076277403252,\n",
       " 2.608524072771503,\n",
       " 2.6414688083454623,\n",
       " 2.634821844676923,\n",
       " 2.621357308554063,\n",
       " 2.6291506272761405,\n",
       " 2.6277949784396744,\n",
       " 2.658592130287073,\n",
       " 2.6141735214126314,\n",
       " 2.635441304151236,\n",
       " 2.585797238271259,\n",
       " 2.6037051216498592,\n",
       " 2.600864706663079,\n",
       " 2.618170098114432,\n",
       " 2.5643056126818276,\n",
       " 2.583503809064285,\n",
       " 2.551342419247714,\n",
       " 2.5807392249379437,\n",
       " 2.5744393422474015,\n",
       " 2.5548904613614836,\n",
       " 2.5606016257789097,\n",
       " 2.5513112308636,\n",
       " 2.5637394787156684,\n",
       " 2.557716559188849,\n",
       " 2.5296034791546633,\n",
       " 2.507345635381722,\n",
       " 2.537593469887491,\n",
       " 2.53315356990911,\n",
       " 2.498782337201039,\n",
       " 2.5322251298656546,\n",
       " 2.501944878863972,\n",
       " 2.541843239089668,\n",
       " 2.5187416222367363,\n",
       " 2.4937692668014093,\n",
       " 2.514735804307096,\n",
       " 2.527630369842187,\n",
       " 2.5045155730236126,\n",
       " 2.49251045058465,\n",
       " 2.47928397517686,\n",
       " 2.535046932795869,\n",
       " 2.498803842864292,\n",
       " 2.502706752901016,\n",
       " 2.4738268201916203,\n",
       " 2.485762598580547,\n",
       " 2.524654106558853,\n",
       " 2.429995171869072,\n",
       " 2.483913303672264,\n",
       " 2.505422183413394,\n",
       " 2.5274422044926124,\n",
       " 2.4807688734052413,\n",
       " 2.457921584894134,\n",
       " 2.484203816579138,\n",
       " 2.4182447405863705,\n",
       " 2.4953984193112606,\n",
       " 2.5016016956043483,\n",
       " 2.458433115248947,\n",
       " 2.494489950580425,\n",
       " 2.459226392545151,\n",
       " 2.4409718433708028,\n",
       " 2.483897709701189,\n",
       " 2.4607620487236117,\n",
       " 2.4404573200633037,\n",
       " 2.459123146837339,\n",
       " 2.469770582816681,\n",
       " 2.42723419994799,\n",
       " 2.463985308920384,\n",
       " 2.4416032272291166,\n",
       " 2.4141212921035766,\n",
       " 2.431157098703482,\n",
       " 2.445970378141542,\n",
       " 2.4564432657419024,\n",
       " 2.41515631055552,\n",
       " 2.4597364291459676,\n",
       " 2.4273260237495187,\n",
       " 2.4386160484924746,\n",
       " 2.4555962552849913,\n",
       " 2.444303918207413,\n",
       " 2.4624259075217236,\n",
       " 2.400527364889724,\n",
       " 2.406280198731622,\n",
       " 2.419173154677614,\n",
       " 2.4508744770524835,\n",
       " 2.457824174670496,\n",
       " 2.426864459806075,\n",
       " 2.4430198128907255,\n",
       " 2.416087548787117,\n",
       " 2.3989235037601992,\n",
       " 2.4196873881939256,\n",
       " 2.4037020274661813,\n",
       " 2.3987317422911016,\n",
       " 2.3887831494835132,\n",
       " 2.4031331563880407,\n",
       " 2.412465880040851,\n",
       " 2.403107874060305,\n",
       " 2.4042683288121927,\n",
       " 2.3763152458788626,\n",
       " 2.3865803653768167,\n",
       " 2.4227818054583024,\n",
       " 2.389359165436441,\n",
       " 2.400498464583571,\n",
       " 2.3724708453832664,\n",
       " 2.3852163748246857,\n",
       " 2.4315926338720106,\n",
       " 2.3511704374358695,\n",
       " 2.3575137820408227,\n",
       " 2.355027935430873,\n",
       " 2.393506991508756,\n",
       " 2.393166151427742,\n",
       " 2.4131571307524546,\n",
       " 2.3944356412524606,\n",
       " 2.408136076939641,\n",
       " 2.345436779462398,\n",
       " 2.366941010865716,\n",
       " 2.3911860492003747,\n",
       " 2.368388159344224,\n",
       " 2.3900020045421213,\n",
       " 2.371966285767471,\n",
       " 2.35191689135289,\n",
       " 2.3742002892666214,\n",
       " 2.376870496640383,\n",
       " 2.386464774089803,\n",
       " 2.3346735474069815,\n",
       " 2.370444396096065,\n",
       " 2.354620640981231,\n",
       " 2.328472987425789,\n",
       " 2.345840579618314,\n",
       " 2.3428855599346967,\n",
       " 2.3481865205569075,\n",
       " 2.318663218207522,\n",
       " 2.307001212007863,\n",
       " 2.348911487955615,\n",
       " 2.339698886047589,\n",
       " 2.343129226965754,\n",
       " 2.3498205591797645,\n",
       " 2.3514832990402392,\n",
       " 2.3761561721173536,\n",
       " 2.362502657820347,\n",
       " 2.331325811989362,\n",
       " 2.313239916579857,\n",
       " 2.349898312020148,\n",
       " 2.3890714277670995,\n",
       " 2.3594104296452914,\n",
       " 2.3270386287543547,\n",
       " 2.3094874226923565,\n",
       " 2.3896723827109105,\n",
       " 2.3357630816619617,\n",
       " 2.322224298107412,\n",
       " 2.3267124068912635,\n",
       " 2.364070079939884,\n",
       " 2.2980628397901985,\n",
       " 2.343833117622507,\n",
       " 2.3168079047306387,\n",
       " 2.337186634487752,\n",
       " 2.3519061252642057,\n",
       " 2.3124332538738765]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11810c978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
